{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import KG_full as AKG\n",
    "from supabase import create_client, Client\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load all configuration from .env\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI config from environment\n",
    "COMPLETIONS_MODEL = os.getenv(\"OPENAI_API_MODEL\", \"gpt-4\")\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = my_api_key\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = my_api_key\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Supabase configuration from environment\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\") or os.getenv(\"SUPABASE_ANON_KEY\")\n",
    "SUPABASE_TABLE = os.getenv(\"SUPABASE_TABLE_NAME\", \"new_documents\")\n",
    "SUPABASE_QUERY_NAME = os.getenv(\"SUPABASE_QUERY_NAME\")\n",
    "SUPABASE_TEXT_COLUMN = os.getenv(\"SUPABASE_TEXT_COLUMN\", \"content\")\n",
    "SUPABASE_METADATA_COLUMN = os.getenv(\"SUPABASE_METADATA_COLUMN\", \"metadata\")\n",
    "SUPABASE_EMBEDDING_COLUMN = os.getenv(\"SUPABASE_EMBEDDING_COLUMN\", \"embedding\")\n",
    "\n",
    "# Create Supabase client if URL and KEY are provided\n",
    "sb: Optional[Client] = None\n",
    "if SUPABASE_URL and SUPABASE_KEY:\n",
    "    sb = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If Supabase is configured, fetch cached chunks; else fall back to local processing\n",
    "if sb is not None:\n",
    "    import json\n",
    "    rows = []\n",
    "    # Prefer RPC if a query/function name is provided\n",
    "    if SUPABASE_QUERY_NAME:\n",
    "        try:\n",
    "            rpc_result = sb.rpc(SUPABASE_QUERY_NAME).execute()\n",
    "            rows = rpc_result.data or []\n",
    "        except Exception as e:\n",
    "            print(f\"RPC '{SUPABASE_QUERY_NAME}' failed, falling back to table select. Error: {e}\")\n",
    "    if not rows:\n",
    "        # Select content, metadata, embedding (if available), and id to derive sources\n",
    "        select_cols = f\"id,{SUPABASE_TEXT_COLUMN},{SUPABASE_METADATA_COLUMN}\"\n",
    "        if SUPABASE_EMBEDDING_COLUMN:\n",
    "            select_cols += f\",{SUPABASE_EMBEDDING_COLUMN}\"\n",
    "        rows = sb.table(SUPABASE_TABLE).select(select_cols).execute().data\n",
    "    \n",
    "    # Extract texts, sources, and optionally cached embeddings\n",
    "    texts = []\n",
    "    sources = []\n",
    "    cached_embeddings = []\n",
    "    has_embeddings = False\n",
    "    \n",
    "    for r in rows:\n",
    "        # Handle both RPC row shapes and table rows\n",
    "        text = r.get(SUPABASE_TEXT_COLUMN, r.get(\"content\", \"\"))\n",
    "        meta = r.get(SUPABASE_METADATA_COLUMN, r.get(\"metadata\")) or {}\n",
    "        # If metadata is a JSON string, try to parse it\n",
    "        if isinstance(meta, str):\n",
    "            try:\n",
    "                meta = json.loads(meta)\n",
    "            except Exception:\n",
    "                meta = {}\n",
    "        # Try a few reasonable keys in metadata for source; fall back to id\n",
    "        src = (\n",
    "            (meta.get(\"source\") if isinstance(meta, dict) else None)\n",
    "            or (meta.get(\"file_name\") if isinstance(meta, dict) else None)\n",
    "            or (meta.get(\"filename\") if isinstance(meta, dict) else None)\n",
    "            or r.get(\"id\")\n",
    "        )\n",
    "        if text is not None and text != \"\":\n",
    "            texts.append(text)\n",
    "            sources.append(str(src) if src is not None else None)\n",
    "            # Check for cached embeddings\n",
    "            emb = r.get(SUPABASE_EMBEDDING_COLUMN) if SUPABASE_EMBEDDING_COLUMN else None\n",
    "            if emb is not None:\n",
    "                cached_embeddings.append(emb)\n",
    "                has_embeddings = True\n",
    "            else:\n",
    "                cached_embeddings.append(None)\n",
    "    \n",
    "    if has_embeddings and len(cached_embeddings) == len(texts):\n",
    "        print(f\"Found {len([e for e in cached_embeddings if e is not None])} cached embeddings in Supabase\")\n",
    "    else:\n",
    "        cached_embeddings = None\n",
    "        print(\"No cached embeddings found, will compute them fresh\")\n",
    "else:\n",
    "    directory = \"raw_data\"\n",
    "    texts, sources = load_and_process_files(directory,\n",
    "                                            chunk_size=200,\n",
    "                                            separator=None)\n",
    "    cached_embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "main_topic = os.getenv(\"MAIN_TOPIC\", \"Knowledge graph, Language Model\")\n",
    "\n",
    "KG_class = AKG.autoKG(texts=texts,\n",
    "                         source=sources,\n",
    "                         embedding_model=EMBEDDING_MODEL,\n",
    "                         llm_model=COMPLETIONS_MODEL,\n",
    "                         openai_api_key=OPENAI_API_KEY,\n",
    "                         main_topic=main_topic,\n",
    "                         embedding=True)\n",
    "\n",
    "# If we have cached embeddings from Supabase, use them\n",
    "if cached_embeddings is not None:\n",
    "    print(\"Using cached embeddings from Supabase\")\n",
    "    # Note: You may need to set KG_class.embeddings directly if autoKG supports it\n",
    "    # This depends on the KG_full implementation\n",
    "    # If not supported, the library will compute embeddings fresh\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# step one: remove duplicates\n",
    "to_keep, to_delete, remains = KG_class.remove_same_text(use_nn=True, n_neighbors=25, thresh=1e-6, update=True)\n",
    "print(len(to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# step two: extract keywords with two methods\n",
    "core_list_1, all_tokens = KG_class.cluster(15,\n",
    "                               clustering_method='NgJordanWeiss',\n",
    "                               max_texts=15,\n",
    "                               select_mtd='similarity',\n",
    "                               prompt_language='English',\n",
    "                               num_topics=10,\n",
    "                               max_length=3,\n",
    "                               post_process=True,\n",
    "                               add_keywords=False,\n",
    "                               verbose=False)\n",
    "print(\"Number of keywords selected:\", len(core_list_1))\n",
    "print(\"Token used:\", all_tokens)\n",
    "\n",
    "core_list_2, all_tokens = KG_class.cluster(15,\n",
    "                               clustering_method='k_means',\n",
    "                               max_texts=15,\n",
    "                               select_mtd='similarity',\n",
    "                               prompt_language='English',\n",
    "                               num_topics=10,\n",
    "                               max_length=3,\n",
    "                               post_process=True,\n",
    "                               add_keywords=True)\n",
    "print(\"Number of keywords selected:\", len(core_list_2))\n",
    "print(\"Token used:\", all_tokens)\n",
    "\n",
    "print(\"Number of keywords:\", len(KG_class.keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% postprocess one: remove substrings\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = KG_class.sub_entry_filter()\n",
    "print(\"Number of keywords:\", len(KG_class.keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% postprocess two: LLM processing\n"
    }
   },
   "outputs": [],
   "source": [
    "_, all_tokens = KG_class.final_keywords_filter()\n",
    "print(\"Token used:\", all_tokens)\n",
    "print(\"Number of keywords:\", len(KG_class.keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "KG_class.make_graph(30)\n",
    "pred_mat, U_mat, A = KG_class.coretexts_seg_individual(k=30, trust_num=5, negative_multiplier=7, seg_mtd='laplace',\n",
    "                                                return_mat=True, connect_threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "KG_class.get_dist_mat()\n",
    "print(KG_class.check_completion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "deg_mat = np.sum(np.array(A.todense()) > 0, axis=0)\n",
    "plt.hist(deg_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "KG_class.save_data(os.path.join('KG_data', 'ref_KG.npy'), include_texts=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
